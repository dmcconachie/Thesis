\chapter{Introduction}

In the 1950s and 1960s George Devol, Joseph Engleberger, and many others began developing machines that were programmable manipulators of objects. Industrial manufacturers, in a desire to reduce labour costs, improve quality, and reduce delivery times were early adopters of this technology. These industrial robots were programmed to perform highly repetitive manipulation of various rigid objects in fixed environments. Key to the robotâ€™s success are the specific program instructions derived from previously measured and calculated features of the real-world objects under manipulation in a fixed environment. The pervasive use of industrial robots performing flawlessly around the globe in factories performing tasks like medical laboratory testing, automobile assembling, or electronics circuit board manufacturing demonstrate the success of programmable manipulators of objects. Complexity has increased, dexterity has improved, and a given robot may be capable of more than one task or can be applied to a different, but previously known size of object or in a different, fully described environment; but, the vast majority of the modeling and planning remains a human creation and is merely programmed into the robot in advance. The industrial robot certainly does not learn.

Indeed, 35 years ago, Michael Brady~\cite{BRADY198579} argued that ``Since robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent.'' Since then, there have been great strides made developing robots with intelligence; one prominent example of this is the self-driving automobile. Like industrial manipulators, a self-driving automobile knows much about its own dimensions and physics but it is constantly relying on computation-intensive processes for intelligence. The robot's task is achievable because the environment being modeled is rigid, the automobile's dynamics are known, and advancements in computing speed have soared, making it possible for the robot to execute a very large, but finite, number of calculations quickly enough for secure and accurate control. Brady went on to say, ``Robotics challenges AI by forcing it to deal with real objects in the real world.'' As true as that statement certainly is for robots such as self-driving automobiles, it is all the more true for robots that manipulate deformable objects possessing an infinite number of degrees of freedom and the inherently incomplete description of the object in all of its possible arrangements. An interesting example of a robot that manipulates deformable objects in current use is the da Vinci surgical robot, well known for its YouTube video demonstrating it stitching a grape back together with thread. Its relevance to this paper is simple: The surgical robot does not learn, plan, or control anything directly; those computationally intensive tasks are performed by a human who controls the robot's manipulating tools. The only way an argument could be made for declaring this surgical robot a learning, autonomous robot would be to assume that it ships from the factory, complete with a human operator who is deemed one of its components. Computational intensity is one of it's biggest hurdles. The computational challenge posed by modeling, planning, and control for deformable objects will be addressed in this dissertation; and, we describe a framework that we successfully used to obtain measurable improvements against that challenge.

Traditional motion planning techniques such as A*, probabilistic roadmaps, and rapidly-exploring random trees were designed with rigid body motion in mind. In this framework contact with the environment is explicitly disallowed. In order to manipulate an object a typical approach is to build a model of the object being grasped; this model is then used to ensure that the object does not collide with anything during a particular motion. In contrast, when working with deformable objects, interaction with the environment is common (and often required), with the deformable object complying to the environment rather than colliding with it. This raises the question ``How accurate do our models need to be?'' There are a broad range of deformable object manipulation tasks that robots have performed without highly accurate models ranging from surgical applications~\cite{Wang2018} to knot-tying~\cite{Huang2015}. While these methods have some success they rely on either a hand designed sequence of actions (or controllers), or a time-consuming data collection phase.

To address these limitations, this dissertation is motivated by two key research questions: (1) How can robots perform a broad range of tasks with deformable objects without high-fidelity models and simulation? and (2) How can robots take advantage of information learned while manipulating deformable objects? By answering these questions we can take a step towards a household robot that is capable of performing a broad range of tasks without any additional training, and can improve its ability to perform the specific tasks that it commonly encounters.

Examples of deformable object manipulation range from domestic tasks like folding clothes to time and safety critical tasks such as robotic surgery. One of the challenges in planning for deformable object manipulation is the high number of degrees of freedom involved; even approximating the configuration of a piece of cloth in 3D with a 4 $\times$ 4 grid results in a 48 degree of freedom configuration space. In addition, the dynamics of the deformable object are difficult to model \cite{Essahbi2012}; even with high-fidelity modeling and simulation, planning for an individual task can take hours \cite{Bai2016}. Local controllers on the other hand are able to very efficiently generate motion, however, they are only able to successfully complete a task when the initial configuration is in the ``attraction basin'' of the goal \cite{Berenson2013, McConachie2018}. We propose combining the strengths of global planning with the strengths of local control while mitigating the weakness of each; we propose a framework for interleaving planning and control which uses global planning to generate gross motion of the deformable object, and a local controller to refine the configuration of the deformable object within the local neighborhood. By separating planning from control we are able to use different representations of the deformable object, each suited to efficient computation for their respective roles.

Two key ideas allow this framework to reliably perform tasks without a time-consuming modelling or data collection phase. First, we do not need to explicitly model and control every part of the deformable object, instead relying on the object's natural compliance in many situations. By doing so we drastically reduce the need for model fidelity, enabling the use of model approximations that do not need to be highly accurate. Second, our framework does not assume that the local controller or global planner are infallible. Instead, we assume that mistakes \textit{will} be made, and implement learning algorithms designed to avoid making the same mistake again. To this end I formulate the controller's task as a Multi-Armed Bandit problem, enabling the controller to chose models based on the current circumstances. For planning we present a planning formulation that explicitly exposes the challenge of planning with model approximations, as well as a method for learning when we can and cannot rely on a model approximation during planning.

This dissertation makes seven contributions towards answering these research questions:
\begin{itemize}
 \item We introduce a more accurate geometric model of how the direction of gripper motion and obstacles affect deformable objects.
 \item We specify a novel stretching avoidance constraint to prevent the object from being overstretched by the robot as part of a local controller, allowing for the use of less accurate models without risking tearing the deformable object.
 \item We formulate the task of the local controller as a Multi-Armed Bandit problem, with each arm representing a model of the deformable object.
 \item We introduce a manipulation framework that interleaves planning and control, choosing each when most useful.
 \item We present a global motion planner to generate gross motion of the deformable object, and provide a proof of probabilistic completeness for our planner, which is valid despite the fact that our system is underactuated and we do not have a steering function.
 \item We introduce a novel formulation of planning in reduced state spaces.
 \item We propose a method for improving the performance of the global planner as mistakes are made due to model approximations, enabling the planner to learn from experience.
\end{itemize}
