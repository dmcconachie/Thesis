\chapter{Bandit-Based Model Selection}

In the previous chapters, we have been working with a single model and a single controller for any given task. When given a new task however, a new choice needs to be made for what model and controller is most suitable. Rather than assuming we have a single high-fidelity model of a deformable object interacting with its environment, our approach is to have multiple models available for use, any one of which may be useful at a given time. We do not assume these models are correct, we simply treat the models as having some measurable \textit{utility} to the task. The \textit{utility} of a given model is the expected reduction in task error when using this model to generate robot motion. As the task proceeds, the utility of a given model may change, making other models more suitable for the current part of the task. However, without testing a model's prediction, we do not know its true utility. Testing every model in the set is impractical, as all models would need to be tested at every step, and performing a test changes the state of the object and may drive it into a local minimum. The key question is then which model should be selected for testing at a given time.

The central contribution of this chapter is framing the model selection problem as a \ac{MAB} problem where the goal is to find the model that has the highest utility for a given task. An arm represents a single model of the deformable object; to ``pull'' an arm is to use the arm's model to generate and execute a velocity command for the robot. The reward received is the reduction in task error after executing the command. In order to determine which model has the highest utility we need to explore the model space, however we also want to exploit the information we have gained by using models that we estimate to have high utility. One of the primary challenges in performing this exploration versus exploitation trade-off is that our models are inherently coupled and non-stationary; performing an action changes the state of the system which can change the utility of every model, as well as the reward of pulling each arm. While there is work that frames robust trajectory selection as a \ac{MAB} problem~\cite{Koval2015}, we are not aware of any previous work which either 1) frames model selection for deformable objects as a \ac{MAB} problem; or 2) addresses the coupling between arms for non-stationary \ac{MAB} problems.

In our experiments, we show how to formulate a \ac{MAB} problem with coupled arms for Jacobian-based models. We perform our experiments on three synthetic systems, and on three deformable object manipulation tasks in the Bullet Physics~\cite{Coumans2010} simulator. We demonstrate that formulating model selection as a \ac{MAB} problem is able to successfully perform all three manipulation tasks. We also show that our proposed \ac{MAB} algorithm outperforms previous \ac{MAB} methods on synthetic trials, and performs competitively on the manipulation tasks.

\input{1_problem_statement}
\input{2_bandit_based_model_selection}
\input{3_mab_formulation}
\input{4_mab_algorithms}
\input{5_results}
