\chapter{Related Work}

Robotic manipulation of deformable objects has been studied in many contexts ranging from surgery to industrial manipulation (see \cite{Khalil2010, Jimenez2012, Sanchez2018deformablesurvey} for surveys). Below we discuss the most relevant methods to the work presented in this dissertation, starting with methods of modelling and simulating deformable objects. We then discuss visual servoing and other local control methods for performing deformable object manipulation tasks. Next we discuss related work for model selection and using multiple models for control. We then describe work relevant to combining local controllers and global planners for accomplishing tasks. We conclude with related work in motion planning for deformable objects and ways to consider topology in planning.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Modelling Deformable Objects}

Much work in deformable object manipulation relies on simulating an accurate model of the object being manipulated. Motivated by applications in computer graphics and surgical training, many methods have been developed for simulating string-like objects \cite{Bergou2008, Rungjiratananon2011} and cloth-like objects \cite{Baraff1998, Goldenthal2007}. The most common simulation methods use Mass-Spring models \cite{Gibson1997, Essahbi2012}, which are generally not accurate for large deformations \cite{Maris2010}, and Finite-Element (FEM) models \cite{Muller2002, Irving2004, Kaufmann2008}. FEM-based methods are widely used and physically well-founded, but they can be unstable when subject to contact constraints, which are especially important in this work. They also require significant tuning and are very sensitive to the discretization of the object. Furthermore, such models require knowledge of the physical properties of the object, such as it's Young's modulus and friction parameters, which we do not assume are known.

Also, we seek a model that can be evaluated very quickly inside an optimal control framework, and Finite-element models, while accurate, can be computationally-expensive to simulate. While methods have been developed to track objects using FEM in real-time \cite{Petit2017}, a controller may need to evaluate the model many times to find an appropriate command, requiring speeds faster than real-time. Specialized models have also been developed, e.g., \cite{Borum2014} and \cite{Bretl2014} focus on elastic rods that are not in contact. We seek a model that works well with rope-like and cloth-like materials that can deform as a result of contact. Finally, researchers have also investigated automatic modeling of deformable objects \cite{Lang2002, Cretu2008}. However, these methods rely on a time-consuming training phase for each object to be modeled, which we would like to avoid.

Our work is complementary to methods that adapt the model of the object during manipulation \cite{Navarro-Alarcon2014, NavarroAlarcon2018, Hu2018deformable_gpr}. Our model can serve as an initial guess and a reference for such methods so that the online adaptation process does not diverge too far from a reasonable model as a result of perception or modeling error. Our modelling methods build on the idea of \textit{diminishing rigidity} Jacobians \cite{Berenson2013} by improving the model by considering the effects of the direction of motion and static obstacles that the deformable object interacts with.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Local Control for Manipulation Tasks}

Given a model such as those above, researchers have investigated various control methods to manipulate deformable objects. Model-based visual servoing approaches bypass planning entirely, and instead use a local controller to determine how to move the robot end-effector for a given task \cite{Hirai2000, Wada2001, Smolen2009}. Other approaches \cite{Berenson2013, Navarro-Alarcon2014, NavarroAlarcon2016, NavarroAlarcon2018} bypass the need for an explicit deformable object model, instead using approximations of the Jacobian to drive the deformable object to the attractor of the starting state. More recent work by \citet{Hu2018deformable_gpr} has enabled the use of Gaussian process regression while controlling a deformable object. Our work builds on \citet{Berenson2013}, capturing overstretching and obstacle avoidance into control constraints that are more effective at preventing damage to the deformable object.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Using Multiple Models}

In order to accomplish a given manipulation task, we need to determine which type of model to use at the current time to compute the next velocity command, as well as how to set the model parameters. Frequently this selection is done manually, however, there are methods designed to make these determinations automatically. Machine learning techniques such as~\cite{Maron1994, Sparks2015} rely on supervised training data in order to intelligently search for the best regression or classification model. These methods are able to estimate the accuracy of each model as training data is processed, pruning models from the training that are unlikely to converge or otherwise outperform models that are kept. These methods are designed for large datasets rather than an online setting where we may not have any training data \textit{a priori}. While it may be possible to adjust these methods to consider model utility instead of model accuracy, it is unclear how to acquire the needed training data for the task at hand without having already performed the task. The most directly applicable methods come from the Multi-Armed Bandit (MAB) literature~\cite{Whittle1988, Auer2002, Gittins2011}. In this framework there are multiple actions we can take, each of which provides us with some reward according to an unknown probability distribution. The problem then is to determine which action to take (which arm to pull) at each time step in order to maximize reward.

The MAB approach is well-studied for problems where the reward distributions are \textit{stationary}; i.e. the distributions do not change over time~\cite{Auer2002, Agrawal2012}. This is not the case for deformable object manipulation; consider the situation where the object is far away from the goal versus the object being at the goal. In the first case there is a possibility of an action moving the object closer to the goal and thus achieving a positive reward; however, in the second case any motion would, at best, give zero reward. In the \textit{contextual bandits} \cite{Langford2008, Slivkins2014} variation of the MAB problem, additional contextual information or features are observed at each timestep, which can be used to determine which arm to pull. Typical solutions map the current features to estimates of the expected reward for each arm using regressions techniques or other metric-space analysis. In order to use contextual bandits for a given task a set of features would need to be engineered, however it is not clear what features to use.

Recent work~\cite{Granmo2010} on non-stationary MAB problems offer promising results that utilize independent Kalman filters as the basis for the estimation of a non-stationary reward distribution for each arm. This algorithm (KF-MANB) provides a Bayesian estimate of the reward distribution at each timestep, assuming that the reward is normally distributed. KF-MANB then performs Thompson sampling~\cite{Agrawal2012} to select which arm to pull, choosing each in proportion to the belief that it is the optimal arm. We build on this approach in this paper to produce a method that also accounts for dependencies between arms by approximating the coupling between arms at each timestep.

For the tasks we address, the reward distributions are both non-stationary as well as \textit{dependent}. Because all arms are operating on the same physical system, pulling one arm both gives us information about the distributions over other arms, as well as changing the future reward distributions of all arms. While work has been done on dependent bandits \cite{Pandey2007, Langford2008}, we are not aware of any work addressing the combination of non-stationary and dependent bandits using a regret-based formulation. Our method for model selection is inspired by KF-MANB, however we directly use coupling between models in order to form a joint reward distribution over all models. This enables a pull of a single arm to provide information about all arms, and thus we spend less time exploring the model space and more time exploiting useful models to perform the manipulation task.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motion Planning for Deformable Objects}

Motion planning for manipulation of deformable objects is an active area of research \cite{Jimenez2012}. \citet{Saha2008} present a Probabilistic Roadmap (PRM) \cite{Kavraki1996} that plans for knot-tying tasks with rope. \citet{Rodriguez2006} study motion planning in fully deformable simulation environments. Their method, based on Rapidly-exploring Random Trees (RRTs) \cite{LaValle2006}, applies forces directly to an object to move it through narrow spaces while using the simulator to compute the resulting deformations. \citet{Frank2011} presented a method that pre-computes deformation simulations in a given environment to enable fast multi-query planning. Other sampling-based approaches have also been proposed \cite{Anshelevich2000a, Lamiraux2001, BurchanBayazit2002, Gayle2005, Moll2006, Roussel2015}. However, all the above methods either disallow contact with the environment or rely on potentially time-consuming physical simulation of the deformable object, which is often very sensitive to physical and computational parameters that may be difficult to determine. In contrast our method uses simplified models for control and motion planning with far lower computational cost.

Our planning method has some similarity to topological \cite{Jaillet2008, Bhattacharya2012} and tethered robot \cite{Brass2015, SoonkyumKim2015} planning techniques; these methods use the topological structure of the space to define homotopy classes, either as a direct planning goal, or as a way to help inform planning in the case of tethered robots. Planning for some deformable objects, in particular rope or string, can be viewed as an extension of the tethered robot case where the base of the tether can move. This extension, however, requires a very different approach to homotopy than is commonly used, particularly when working in three-dimensional space instead of a planar environment. In our work we use \textit{visiblity deformations} from \cite{Jaillet2008} as a way to encode homotopy-like classes of configurations.

Previous approaches to proving probabilistic completeness for efficient planning of underactuated systems rely on the existence of a steering function to move the system from one region of the state space to another, or choosing controls at random \cite{LaValle2001, Karaman2013, Kunz2015, LiAOKP2016}. For deformable objects, a computationally-efficient steering function is not available, and using random controls can lead to prohibitively long planning times. \citet{Roussel2015} bypass this challenge by analyzing completeness in the submanifold of quasi-static contact-free configurations of a extensible elastic rods. In contrast, we show that our method is probabilistically complete even when contact between the deformable object and obstacles is considered along the path. Note that it is especially important to allow contact at the goal configuration of the object to achieve coverage tasks. \citet{LiAOKP2016} present an efficient asymptotically-optimal planner which does not need a steering function, however, they do rely on the existence of a contact free trajectory where every point in the trajectory is in the interior of the valid configuration space. Our proof of probabilistic completeness is based on \citet{LiAOKP2016}, but we allow for the deformable object to be in contact with obstacles along a given trajectory.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Interleaving Planning and Control for Deformable Object Manipulation}

The use of a local controller is not considered in the above methods, instead relying on a global planner (and thus implicitly the accuracy of the simulator) to generate a path that completes the entire task. In contrast, our framework combines the strengths of global planning with the strengths of local control in order to perform tasks.

\citet{Park2014Interleaving} considered interleaving planning and control for arm reaching tasks in rigid unknown environments. In their method, they assume an initially unknown environment in which they plan a path to a specific end-effector position. This path is then followed by a local controller until the task is complete, or the local controller gets stuck. If the local controller gets stuck, then a new path is planned and the cycle repeats. In contrast, our controller is performing the task directly rather than following a planned reference trajectory, incorporating deadlock prediction into the execution loop, while our global planner is planning for both the robot motion as well as the deformable object stretching constraint.

Approaches based on learning from demonstration avoid planning and deformable object modelling challenges entirely by using offline demonstrations to teach the robot specific manipulation tasks \cite{Huang2015, Schulman2016}; however, when a new task is attempted a new training set needs to be generated. In our application we are interested in a way to manipulate a deformable object without a high-fidelity model or training set available \textit{a priori}. For instance, imagine a robot encountering a new piece of clothing for a new task. While it may have models for previously-seen clothes or training sets for previous tasks, there is no guarantee that those models or training sets are appropriate for the new task.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Learning for Planning in Reduced State Spaces}

In terms of applying machine learning to control and planning, prior work has primarily used learned dynamics models for control \cite{Finn2017, Banijamali2017, Jia2018, Zhang2019, Sutanto2019}. Recent work \cite{ichter2019} has also explored planning in a learned reduced space, but they do not consider the error in a reduced model's prediction when planning. Visual Planning and Acting (VPA)~\cite{vpa2019rss} learns a latent transition model based on visual input for planning. This work uses on a classifier to prune infeasible transitions during planning. However, despite this classifier, only 15\% of generated plans were visually plausible, with only 20\% of the visually plausible plans being executable. When considering machine learning methods in this dissertation we do not focus on learning a reduction but rather on creating a framework that can be used to overcome limitations in a given model reduction.