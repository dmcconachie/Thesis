\chapter{Discussion and Future Work}

This dissertation presented a framework for autonomously manipulating deformable objects, focusing on methods that can be used without a time-consuming modelling phase, and without high-fidelity simulation. We have focused on techniques and algorithmic choices that enable the robot to learn from performing tasks, improving the robot's ability to manipulate deformable objects and perform interesting tasks. Our contributions in modelling and control do not involve learning directly, but they form part of the basis from which the robot is able to acquire experience from which to learn. These methods could also be combined with other techniques such as residual physics~\cite{zengtossingbot} to integrate analytical methods with learning based approaches.

Our initial goal for integrating learning into the planning process was to do so in an online fashion; i.e., after making a plan that leads to getting caught on a hook we would like to avoid repeating a similar mistake when generating the next plan. The key challenge here is how to evaluate similarity; what does it mean for two transitions to be similar, particularly when accounting for the local environment? By using a classifier directly in state transition space we were able to avoid making the same mistake on a given hook, but this approach does not generalize to different obstacle configurations. Being able to learn quickly from a small number of mistakes and to generalize that experience to new scenarios is a skill that will enable robots to move from the lab to unstructured environments like the home.

Chapter~\ref{chap:mab} introduced the idea of using multiple models for control, switching between them as the task progressed; we experimented with a similar idea during the planning process. There are three key challenges that need to be overcome to make this approach workable. First, we need a way to acquire multiple models that might be useful in various situations. The representations used by these models would need to be \textit{interchangeable}, i.e. in order to switch to a different model at a later timestep we need to be able to convert between the representations used by each model. Second, we need a way to evaluate the performance of a model in a way that allows us to make decisions during planning about which model to use. If we are using multiple models during the planning processes, disentangling the effects of choices made early in the planning process from their long term effects later in the plan is difficult. In Chapter~\ref{chap:learning_when_to_trust} we addressed this credit assignment problem for a single model by introducing a conservative model-accuracy based supervised classification problem; this approach has the potential to apply to a multi-model approach, but the effects of switching between models while planning needs investigating. Third, it's not clear how and when to use predictions from multiple models during planning; \citet{calderWAFR} introduced a clustering approach to managing the exponential growth of the planning tree if multiple predictions are considered at each timestep which, could be a promising direction of research.

One of the limiting assumptions of this dissertation is the representation of the deformable object as a set of points, accurately and directly sensed. By making these assumptions we are requiring far more from our perception systems than they are generally capable of. For example if we consider a pile of clothes, being able to disambiguate between each clothing item that the robot can see, as well as estimating the configuration of every item is prohibitive. Instead, we may want to consider task specific representations that enable a higher level of reasoning over actions rather than a point-wise representation. It is an open question how to come by these representations, or how to know when to use a given representation for the task at hand. In this work, we used two representations, one for local control purposes and another for global planning. By using these different representations we were able to write algorithms focused on different parts of an overall task, and then combine these algorithms together into a single framework. Other representations may allow for a different way of thinking about deformable object manipulation that may be better suited to other tasks.

In this dissertation we hand-designed the decisions of when to use each representation and the associated method for manipulating the deformable object. Extending this framework to a broader set of abilities and representations naturally leads to approaches such as task and motion planning techniques which reason over discrete choices (for example, which representation/algorithm to use) along with continuous variables (for example, where to grasp). A great deal more work is needed in this area as we work towards integrating deformable object manipulation tools into a general robotics solution.

Some of the limitations imposed by our interleaving framework may be addressed by closing the loop on the execution of plans generated by RRT-EB. By monitoring the deformable object while a plan is executed we can quickly determine when the deformable object has diverged from the planned path, but it is an open question how to recover from a divergence. Can we define a local controller that reasons about how close our VEB model reduction is representing the true configuration of the deformable object and close the loop at this level? While this may be possible in some circumstances, in general we believe that something like our interleaving framework will always be needed in order to respond to unmodelled aspects of problems and continue with a given task.

One of the key differences between rigid objects verses deformable object manipulation is that deformable objects are pliable; we explicitly took advantage of this when designing our VEB model reduction and planner. That said, we have not taken advantage of that compliance as an explicit manipulation tool; the directional rigidity model in Section~\ref{sec:constrained_model} can enable a controller to take advantage of interactions with the environment, but it does so without explicitly reasoning about it. It's not clear how to take advantage of such contact in a principled fashion; is including contact in the modelling process enough? Is it better to use contact as a way of creating funnels for chaining actions or controllers? Can we exploit contact in a way that helps reduce the scope of the problem that a task and motion planning framework needs to solve?

In this dissertation, we have presented a framework and series of algorithms, supported by successful simulations and lab robot performance, that successfully answers two primary questions that motivated this research. Firstly, our robot successfully reduced the amount of time-consuming modelling and data collection necessary to perform tasks with rope and cloth by interleaving planning and control. By using different representations for each component, we are able to perform these tasks without high-fidelity modelling or simulation. Secondly, we integrated ideas from decision theory and machine learning into classical motion planning and control approaches in order to overcome the limitations of using low-fidelity modelling and approximation methods by learning from the robot's experience gained while using these approximations to perform manipulation tasks.

However, some questions remain arising from the inherent difference between rigid body manipulation and deformable object manipulation, generating a number of worthwhile future research endeavors, as presented above. Loosely grouped as related to planning and online learning, they include topics such as learning to avoid repeating similar mistakes, evaluating and defining ``similar'', integrated task planning and motion planning, and how to achieve a modicum of intuition such that the robot is able to understand what success looks like when encountering new tasks or environments. Topics grouped around the idea of modelling include improved use of a wider variety of types of models, real-world sensing of the deformable object and how it is represented, and how to take better advantage of the compliant nature of the object. Control-related questions include how to better incorporate interleaving, quicker discovery of divergence from the desired path, and of course the ongoing challenges of dexterous manipulation.

