\section{Problem Statement}
\label{sec:main_problem_statement}

Define the robot configuration space to be $\cspace_r$. We assume that the robot configuration can be measured exactly. Denote an individual robot configuration as $\robotconfig \in \cspace_r$. This set can be partitioned into a valid and invalid set. The valid set is referred to as $\cfree_r$, and is the set of configurations where the robot is not in collision with the static geometry of the world. The invalid set is referred to as $\cinv_r = \cspace_r \setminus \cfree_r$.

We assume that our model of the robot is purely kinematic, with no higher order dynamics. We assume that the robot has two end-effectors that are rigidly attached to the object. The configuration of a deformable object is a set $\deformconfig \subset \reals^3$ of $\numdeformpoints = | \deformconfig |$ points. We assume that we have a method of sensing $\deformconfig$. The rest of the environment is denoted $\obstacle$ and is assumed to be both static, and known exactly. We assume that the robot moves slowly enough that we can treat the combined robot and deformable object as quasi-static. Let the function $f(\robotconfig, \deformconfig, \robotvelocity)$ map the system configuration $(\robotconfig, \deformconfig)$ and robot movement $\robotvelocity$ to the corresponding deformable object movement $\deformvelocity$.

We define a task based on a set of $\numtargetpoints$ target points $\deformtarget \subset \reals^3$, a function $\errorfunction: \deformconfig \times \deformtarget \rightarrow \reals^{\geq 0}$, which measures the alignment error between $\deformconfig$ and $\deformtarget$, and a termination function $\terminationcondition (\deformconfig)$ which indicates if the task is finished. Let a robot controller be a function $\controller \left(\robotconfig, \deformconfig, \deformtarget \right)$\footnote{A specific controller may have additional parameters (such as gains in a PID controller), but we do not include such parameters here to keep $\controller(\dots)$ in a more general form.} which maps the system state $\left( \robotconfig, \deformconfig \right)$ and alignment targets $\deformtarget$ to a desired robot motion $\robotcommandvel$. In this work we restrict our discussion to tasks and controllers of the form introduced in the previous chapters; these controllers are local, i.e. at each time $t$ they choose an incremental movement $\robotcommandvel$ which reduces the alignment error as much as possible at time $t + 1$. 

The problem we address in this work is how to find a sequence of $\taskexecutiontime$ robot commands $\{ \robotcommandvel[1], \dots, \robotcommandvel[\taskexecutiontime] \} = \robotcommandsequence$ such that each motion is feasible, i.e. it should not bring the grippers into collision with obstacles, should not cause the object to stretch excessively, and should not exceed the robot's maximum velocity $\maxrobotvel$. Let these feasibility constraints be represented by $A(\robotvelocity) = 0$. Then the problem we seek to solve is:
\begin{equation}
    \begin{aligned}
        & \text{find}   & & \robotcommandsequence \\
        & \text{s.t.}   & & \terminationcondition(\deformconfig_{\taskexecutiontime}) = \texttt{true} \\
        &               & & A(\robotcommandvel[t])                                    = 0, \; t = 1, \dots, \taskexecutiontime
    \end{aligned}
    \label{eqn:main_problem_statement}
\end{equation}
where $\deformconfig_{\taskexecutiontime}$ is the configuration of the deformable object after executing $\robotcommandsequence$.

Solving this problem directly is impractical in the general case for two major reasons. First, modeling a deformable object accurately is very difficult in the general case, especially if it contacts other objects or itself. Second, even given a perfect model, computing precise motion of the deformable object requires physical simulation, which can be very time consuming inside a planner/controller where many potential movements need to be evaluated. We seek a method which does not rely on high-fidelity modelling and simulation; instead we present a framework combining both global planning and local control to leverage the strengths of each in order to efficiently perform the task.
